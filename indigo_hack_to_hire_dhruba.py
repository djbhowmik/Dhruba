# -*- coding: utf-8 -*-
"""Indigo_Hack_to_Hire_Dhruba.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-HTJubScGQeDVpSBNAyTl_QSoxfu23Ck

# **1. Importing Dataset**
"""

import pandas as pd
df = pd.read_json("hf://datasets/toughdata/quora-question-answer-dataset/Quora-QuAD.jsonl", lines=True)

df.head(10)

"""# **2. Analyzing Dataset**"""

print(df.info())
print(df.describe())
print(df.shape)
print(df.isnull().sum())
print(df.dtypes)
print(df.nunique())
print(df['question'].value_counts())
print(df['answer'].value_counts())

"""# **3. Data Cleaning**"""

# Installing library to Expand Contractions
!pip install contractions

# Installing library to Expand Abbreviations
!pip install abbrev

import contractions

def expand_contractions(data):
    return contractions.fix(data)

df['answer']=df['answer'].apply(lambda z: expand_contractions(z))
df['question']=df['question'].apply(lambda z: expand_contractions(z))

def expand_abbreviations(text):
    choices = ['As Soon As Possible', 'For Your Information', 'By The Way', 'In My Opinion', 'I Don\'t Know', 'If I Remember Correctly', 'To Be Honest', 'Too Long; Didn\'t Read', 'For What It\'s Worth', 'Good Game', 'No Problem', 'Please', 'Thanks', 'See You', 'I See', 'Just Kidding', 'Laugh Out Loud', 'Oh My God', 'Rolling On the Floor Laughing', 'Shaking My Head', 'You Only Live Once']
    abbreviations = ['ASAP', 'FYI', 'BTW', 'IMO', 'IDK', 'IIRC', 'TBH', 'TL;DR', 'FWIW', 'GG', 'NP', 'PLZ', 'THX', 'CU', 'IC', 'JK', 'LOL', 'OMG', 'ROFL', 'SMH', 'YOLO']
    abbreviations_dict = {abbreviation.lower(): choice for abbreviation, choice in zip(abbreviations, choices)}

    words = text.split()
    expanded_words = []
    for word in words:
        word = word.strip('.,;:!?"\'')

        if word.upper() in abbreviations:
            expanded_words.append(abbreviations_dict[word.lower()])
        else:
            expanded_words.append(word)
    return ' '.join(expanded_words)

df['answer']=df['answer'].apply(lambda z: expand_abbreviations(z))
df['question']=df['question'].apply(lambda z: expand_abbreviations(z))

import re
#Removes Punctuations
def punctuations(data):
    tag=re.compile(r'[^\w\s]')
    data=tag.sub(r'',data)
    return data

#Removes HTML syntaxes
def html(data):
    html_tag=re.compile(r'<.*?>')
    data=html_tag.sub(r'',data)
    return data

#Removes URL data
def url(data):
    url_pattern = re.compile(r"(https?:\/\/(?:[-\w]+\.)+[a-zA-Z]{2,}(?:\/[^\s]*)?)|(www\.(?:[-\w]+\.)+[a-zA-Z]{2,}(?:\/[^\s]*)?)")
    data = url_pattern.sub(r'', data)
    return re.sub(r'\s+', ' ', data).strip()

#Removes Emojis
def emoji(data):
    emoji_clean= re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    data=emoji_clean.sub(r'',data)
    url_clean= re.compile(r"https://\S+|www\.\S+")
    data=url_clean.sub(r'',data)
    return data

df['question']=df['question'].apply(lambda z: punctuations(z))
df['question']=df['question'].apply(lambda z: html(z))
df['question']=df['question'].apply(lambda z: url(z))
df['question']=df['question'].apply(lambda z: emoji(z))

df['answer']=df['answer'].apply(lambda z: punctuations(z))
df['answer']=df['answer'].apply(lambda z: html(z))
df['answer']=df['answer'].apply(lambda z: url(z))
df['answer']=df['answer'].apply(lambda z: emoji(z))

"""# **4. Data Preparation**"""

def lower_case(sentence):
    return sentence.lower()

df['question']=df['question'].apply(lambda z: lower_case(z))
df['answer']=df['answer'].apply(lambda z: lower_case(z))

df.head(20)

"""# **5. Data Vizualizations**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Calculate the length of each question and answer
df['question_length'] = df['question'].apply(len)
df['answer_length'] = df['answer'].apply(len)

# Plot a histogram of question lengths
plt.figure(figsize=(10, 6))
sns.histplot(df['question_length'], bins=10)
plt.title('Distribution of Question Lengths')
plt.xlabel('Length')
plt.ylabel('Frequency')
plt.show()

# Plot a scatter plot of question length vs answer length
plt.figure(figsize=(10, 6))
sns.scatterplot(x='question_length', y='answer_length', data=df)
plt.title('Relationship between Question and Answer Lengths')
plt.xlabel('Question Length')
plt.ylabel('Answer Length')
plt.show()

from wordcloud import WordCloud

# Create a word cloud of the questions
wordcloud = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(" ".join(df['question']))

plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

nltk.download('punkt')
nltk.download('stopwords')
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter
import nltk
from nltk.tokenize import word_tokenize

# Combine the questions and answers into a single string
text = " ".join(df['question']) + " " + " ".join(df['answer'])

# Tokenize the text
tokens = word_tokenize(text)

# Remove stopwords
stopwords = set(nltk.corpus.stopwords.words('english'))
tokens = [token for token in tokens if token.lower() not in stopwords]

# Count the frequency of each word
word_freq = Counter(tokens)

# Get the top 10 most common words
top_words = word_freq.most_common(10)

# Plot a bar chart of the top 10 most common words
plt.figure(figsize=(10, 6))
sns.barplot(x=[word for word, freq in top_words], y=[freq for word, freq in top_words])
plt.title('Top 10 Most Common Words')
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.show()

"""# **6. Saving Processed Dataset to Excel**"""

# Create a DataFrame
DhruvJB = pd.DataFrame(df)

# Save the DataFrame to an Excel file
DhruvJB.to_excel('Quora_DataSet1.xlsx', index=False)

# This should give the final cleaned dataset

"""# **7. Implementing T5 NLP Model**"""

import pandas as pd
x='Quora.xlsx'
x=pd.read_excel(x)
x.head()

!pip install torch
import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
import pandas as pd

# Load pre-trained T5 model and tokenizer
model = T5ForConditionalGeneration.from_pretrained('t5-small')
tokenizer = T5Tokenizer.from_pretrained('t5-small')

def answer_question(question, context):
    input_text = f"answer: {question} context: {context}"
    input_ids = tokenizer.encode(input_text, return_tensors='pt', max_length=512, truncation=True)
    res = model.generate(input_ids)
    answer = tokenizer.decode(res[0], skip_special_tokens=True)
    return answer

# Assume x is a pandas dataframe with columns 'question' and 'answer'
output_data = []
for i, row in x.iterrows():
    question = row['question']
    context = row['answer']
    answer = answer_question(question, context)
    output_data.append({
        'Question': question,
        'Context': context,
        'Generated Answer': answer
    })

output_df = pd.DataFrame(output_data)
print(output_df)

from nltk.translate.bleu_score import sentence_bleu

bleu_scores = []
for i in range(len(output_df)):
    question = output_df.loc[i, 'Context'].split()
    context = output_df.loc[i, 'Generated Answer'].split()
    answerb = sentence_bleu([question], context)
    bleu_scores.append(answerb)
    print(answerb)

output_df['BLEU Score'] = bleu_scores

output_df['BLEU Score'] = output_df.apply(lambda row: sentence_bleu([row['Context'].split()], row['Generated Answer'].split()), axis=1)

!pip install rouge-score

rogue_scoresT5 = []

def calculate_rouge(question, context):
    # implement your ROUGE score calculation logic here

    from rouge_score import rouge_scorer
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)
    scores = scorer.score(question, context)
    return scores

for i in range(len(output_df)):
    question = output_df.loc[i, 'Context']
    context = output_df.loc[i, 'Generated Answer']
    if isinstance(context, float):
        context = str(context)
    if isinstance(question, float):
        question = str(question)
    answerr = calculate_rouge(question, context)
    rogue_scoresT5.append(answerr)
    print(answerr)

output_df['T5 Rogue Score'] = rogue_scoresT5

output_df

"""# **8. Implementing Bidirectional Encoder**"""

import pandas as pd
import torch
from transformers import BertTokenizer, BertForQuestionAnswering

# Load the BERT model and tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')

# Define a function to answer questions
def answer_question(question, context):
    inputs = tokenizer.encode_plus(
        question,
        context,
        add_special_tokens=True,
        max_length=512,
        return_attention_mask=True,
        return_tensors='pt',
        truncation=True
    )
    outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])
    answer_start = torch.argmax(outputs.start_logits)
    answer_end = torch.argmax(outputs.end_logits) + 1
    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))
    return answer

# Create a new DataFrame to store the answers
answers_df = pd.DataFrame(columns=['question', 'answer'])

# Test the function and store the answers in the DataFrame
for i in range(len(x)):
    question = x.loc[i, 'question']
    context = x.loc[i, 'answer']
    answer = answer_question(question, context)
    answers_df.loc[i] = [question, answer]

# Print the answers DataFrame
print(answers_df)

bleu_scores = []
for i in range(len(answers_df)):
    question = answers_df.loc[i, 'question'].split()
    context = answers_df.loc[i, 'answer'].split()
    answerb = sentence_bleu([question], context)
    bleu_scores.append(answerb)
    print(answerb)

answers_df['BLEU Score'] = bleu_scores

rogue_scoresT5 = []

def calculate_rouge(question, context):
    # implement your ROUGE score calculation logic here

    from rouge_score import rouge_scorer
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)
    scores = scorer.score(question, context)
    return scores

for i in range(len(answers_df)):
    question = answers_df.loc[i, 'question']
    context = answers_df.loc[i, 'answer']
    if isinstance(context, float):
        context = str(context)
    if isinstance(question, float):
        question = str(question)
    answerr = calculate_rouge(question, context)
    rogue_scoresT5.append(answerr)
    print(answerr)

answers_df['T5 Rogue Score'] = rogue_scoresT5

answers_df

"""# **9. Implementing GPT2**"""

import pandas as pd
x='Quora2.xlsx'
x=pd.read_excel(x)
x.head()

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import pandas as pd

# Load pre-trained GPT-2 model and tokenizer
model = GPT2LMHeadModel.from_pretrained('gpt2')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

def answer_question(question, context):
    input_text = f"{question} {context}"
    input_ids = tokenizer.encode(input_text, return_tensors='pt', max_length=1024, truncation=True)

    # Generate position IDs to match the input length
    position_ids = torch.arange(input_ids.shape[1]).unsqueeze(0)

    output = model.generate(input_ids,
                           max_new_tokens=50,
                           early_stopping=True,
                           position_ids=position_ids)  # Pass position IDs to the model
    answer = tokenizer.decode(output[0], skip_special_tokens=True)
    return answer

# Assume x is a pandas dataframe with columns 'question' and 'context'
ans_df = pd.DataFrame(columns=['question', 'context', 'answer'])

# Assume x is a pandas dataframe with columns 'question' and 'context'
for i in range(len(x)):
    question = x.loc[i, 'question']
    context = x.loc[i, 'answer']  # Assuming 'answer' column contains the context
    if context:  # Check if context is not empty or None
        answer = answer_question(question, context)
        print(f"Question: {question}")
        print(f"Answer: {answer}")
        print()
        ans_df.loc[i] = [question, context, answer]
    else:
        print(f"Question: {question}")
        print("No context available")
        print()
        ans_df.loc[i] = [question, context, "No context available"]

print(ans_df)

bleu_scores = []
for i in range(len(ans_df)):
    question = ans_df.loc[i, 'question'].split()
    context = ans_df.loc[i, 'answer'].split()
    answerb = sentence_bleu([question], context)
    bleu_scores.append(answerb)
    print(answerb)

ans_df['BLEU Score'] = bleu_scores

rogue_scoresT5 = []

def calculate_rouge(question, context):
    # implement your ROUGE score calculation logic here

    from rouge_score import rouge_scorer
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)
    scores = scorer.score(question, context)
    return scores

for i in range(len(ans_df)):
    question = ans_df.loc[i, 'question']
    context = ans_df.loc[i, 'answer']
    if isinstance(context, float):
        context = str(context)
    if isinstance(question, float):
        question = str(question)
    answerr = calculate_rouge(question, context)
    rogue_scoresT5.append(answerr)
    print(answerr)

ans_df['T5 Rogue Score'] = rogue_scoresT5

ans_df

"""# **10. Comapring Results**"""

output_df.to_excel('Quora_T5.xlsx', index=False)

answers_df.to_excel('Quora_BERT.xlsx', index=False)

ans_df.to_excel('Quora_GPT.xlsx', index=False)

import pandas as pd
x='Quora_T5.xlsx'
df=pd.read_excel(x)
df.head()

import pandas as pd
import matplotlib.pyplot as plt

# Calculate the average of the numerical columns
averages = df[['BLEU_T5', 'Rogue_T5', 'BLEU_BERT', 'Rogue_BERT', 'BLUE_GPT', 'Rogue_GPT']].mean()

# Print the averages
print(averages)

# Plot the averages
plt.figure(figsize=(10,6))
plt.bar(averages.index, averages.values)
plt.xlabel('Metric')
plt.ylabel('Average Value')
plt.title('Average Values of Metrics')
plt.show()